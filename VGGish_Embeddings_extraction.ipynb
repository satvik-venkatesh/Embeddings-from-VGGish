{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGGish Embeddings extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik94/Embeddings-from-VGGish/blob/master/VGGish_Embeddings_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPUqQtVHKggi",
        "colab_type": "text"
      },
      "source": [
        "#VGGish Audio Embedding Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuhXsmvIKL62",
        "colab_type": "text"
      },
      "source": [
        "This colab demonstrates how to extract the AudioSet embeddings, using a VGGish deep neural network (DNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAE4O-fK-RW2",
        "colab_type": "text"
      },
      "source": [
        "#Importing and Testing the VGGish System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKSLc0bIB1QS",
        "colab_type": "text"
      },
      "source": [
        "Based on the directions at: https://github.com/tensorflow/models/tree/master/research/audioset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1YVQb-MBiUx",
        "colab_type": "code",
        "outputId": "bc1ddb05-6c71-4712-f8a6-bdf1e2ee15d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "!pip install numpy scipy\n",
        "!pip install resampy tensorflow six\n",
        "!pip install tf_slim\n",
        "!pip install soundfile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python2.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.0/python2.7 (1.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python2.7/dist-packages (from resampy) (0.40.1)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python2.7/dist-packages (from resampy) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python2.7/dist-packages (from resampy) (1.16.4)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: functools32>=3.2.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.2.3.post2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.0/python2.7 (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.post1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.3.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python2.7/dist-packages (from numba>=0.32->resampy) (1.0.2)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python2.7/dist-packages (from numba>=0.32->resampy) (0.29.0)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python2.7/dist-packages (from numba>=0.32->resampy) (3.4.0.3)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (44.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Installing collected packages: tensorflow-estimator\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorflow-estimator-1.15.1\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/91/9bb704ddaa15660354afa6858b35445a1430cea3ac86cdbe137d27913e58/tf_slim-1.0-py2.py3-none-any.whl (117kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python2.7/dist-packages (from tf_slim) (0.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n",
            "Requirement already satisfied: enum34; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.1.6)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.0\n",
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python2.7/dist-packages (from soundfile) (1.12.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python2.7/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN7yMJ3BBu_Q",
        "colab_type": "code",
        "outputId": "155322e9-7d4e-43fb-bbb7-fcdebe103474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 32913, done.\u001b[K\n",
            "remote: Total 32913 (delta 0), reused 0 (delta 0), pack-reused 32913\u001b[K\n",
            "Receiving objects: 100% (32913/32913), 511.79 MiB | 32.34 MiB/s, done.\n",
            "Resolving deltas: 100% (21099/21099), done.\n",
            "Checking out files: 100% (2438/2438), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOutr-RFCFfD",
        "colab_type": "code",
        "outputId": "ec1b764b-c16b-4a16-fb6b-7cc7e9b7cf01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check to see where are in the kernel's file system.\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVgYDQ2CG4K",
        "colab_type": "code",
        "outputId": "ae7f0fdf-5a20-4334-b86d-9fe11a261438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Grab the VGGish model\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  277M  100  277M    0     0  56.5M      0  0:00:04  0:00:04 --:--:-- 59.0M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 73020  100 73020    0     0   304k      0 --:--:-- --:--:-- --:--:--  306k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEl3w-RjCPwp",
        "colab_type": "code",
        "outputId": "fd0789f4-c434-4e78-b446-1e932081c2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Make sure we got the model data.\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models\tsample_data  vggish_model.ckpt\tvggish_pca_params.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbtPmmX-CTHB",
        "colab_type": "code",
        "outputId": "e768b139-df64-41a7-b44d-5470062e8419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Verify the location of the VGGish source files\n",
        "!ls models/research/audioset/vggish"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mel_features.py\t\t  vggish_input.py\t vggish_slim.py\n",
            "README.md\t\t  vggish_params.py\t vggish_smoke_test.py\n",
            "vggish_inference_demo.py  vggish_postprocess.py  vggish_train_demo.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oApFn6gzCvsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the source files to the current directory.\n",
        "!cp models/research/audioset/vggish/* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaMrmOEvC7L4",
        "colab_type": "code",
        "outputId": "7b5c2e51-1eaf-44ac-96f9-7f429ee96984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Make sure the source files got copied correctly.\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mel_features.py\t\t  vggish_input.py\t vggish_slim.py\n",
            "models\t\t\t  vggish_model.ckpt\t vggish_smoke_test.py\n",
            "README.md\t\t  vggish_params.py\t vggish_train_demo.py\n",
            "sample_data\t\t  vggish_pca_params.npz\n",
            "vggish_inference_demo.py  vggish_postprocess.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BKF-1dzDhnz",
        "colab_type": "code",
        "outputId": "66d9c56f-5264-4a28-de92-09a2fb0f9550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run the test, which also loads all the necessary functions.\n",
        "from vggish_smoke_test import *"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0324 09:13:11.653609 139728207759232 deprecation.py:323] From /tensorflow-1.15.0/python2.7/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing your install of VGGish\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0324 09:13:15.114495 139728207759232 deprecation.py:323] From /tensorflow-1.15.0/python2.7/tensorflow_core/contrib/layers/python/layers/layers.py:1057: apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Log Mel Spectrogram example:  [[-4.47297436 -4.29457354 -4.14940631 ... -3.9747003  -3.94774997\n",
            "  -3.78687669]\n",
            " [-4.48589533 -4.28825497 -4.139964   ... -3.98368686 -3.94976505\n",
            "  -3.7951698 ]\n",
            " [-4.46158065 -4.29329706 -4.14905953 ... -3.96442484 -3.94895483\n",
            "  -3.78619839]\n",
            " ...\n",
            " [-4.46152626 -4.29365061 -4.14848608 ... -3.96638113 -3.95057575\n",
            "  -3.78538167]\n",
            " [-4.46152595 -4.2936572  -4.14848104 ... -3.96640507 -3.95059567\n",
            "  -3.78537143]\n",
            " [-4.46152565 -4.29366386 -4.14847603 ... -3.96642906 -3.95061564\n",
            "  -3.78536116]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0324 09:13:15.233644 139728207759232 deprecation.py:323] From /tensorflow-1.15.0/python2.7/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VGGish embedding:  [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.16137305 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.8069579\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.36792767 0.0358243  0.         0.         0.\n",
            " 0.         0.38027033 0.13755944 0.9174706  0.8065635  0.\n",
            " 0.         0.         0.         0.04036267 0.7076243  0.\n",
            " 0.497839   0.24081804 0.2156543  0.884923   1.1956801  0.6706196\n",
            " 0.20779456 0.0163987  0.17471854 0.         0.         0.2510081\n",
            " 0.         0.         0.14607906 0.         0.3988705  0.30542105\n",
            " 0.12896752 0.         0.         0.         0.         0.\n",
            " 0.53851354 0.         0.         0.04941072 0.42527407 0.18537286\n",
            " 0.         0.         0.14753528 0.         0.         0.69933873\n",
            " 0.45541185 0.05174828 0.         0.01992542 0.         0.\n",
            " 0.5181578  0.5655761  0.6587975  0.         0.         0.41056335\n",
            " 0.         0.         0.         0.25765193 0.23232111 0.24026448\n",
            " 0.         0.         0.         0.         0.         0.26523754\n",
            " 0.         0.48460817 0.         0.         0.19325797 0.\n",
            " 0.20123355 0.         0.03368623 0.         0.         0.\n",
            " 0.         0.17836352 0.02474906 0.0688998  0.         0.\n",
            " 0.         0.08246288 0.         0.         0.         0.\n",
            " 0.         0.        ]\n",
            "Postprocessed VGGish embedding:  [169  10 154 127 191  66 124  69 157 232 142  21 128 131  43   3  33 111\n",
            " 198 153  76 255 194  60  71 179 146 131 167  60  79  76 192  84 102 160\n",
            "  23  91 173  13 149 186 115 202 252 163  84 145 107 255   5 198  81   0\n",
            " 203 110  35 104 101 131 255   0   0 158 136  74 115 152  77 154  54 151\n",
            "  82 243  57 116 165 153  85 181 152   0 255 122  29 255  46 105 110  43\n",
            "   0  90  58  13 255 108  96 255  84 121 255  75 176 111 176  64  83 231\n",
            " 255  82 255  94  81 144  99 173 255   0   0 158  31 230 112 255   0 255\n",
            "  20 255]\n",
            "\n",
            "Looks Good To Me!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlFWzFsS-ry7",
        "colab_type": "text"
      },
      "source": [
        "#Using the VGGish System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7t20mo27zKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import vggish_slim\n",
        "import vggish_params\n",
        "import vggish_input\n",
        "import soundfile as sf\n",
        "\n",
        "def CreateVGGishNetwork(hop_size=0.96):   # Hop size is in seconds.\n",
        "  \"\"\"Define VGGish model, load the checkpoint, and return a dictionary that points\n",
        "  to the different tensors defined by the model.\n",
        "  \"\"\"\n",
        "  vggish_slim.define_vggish_slim()\n",
        "  checkpoint_path = 'vggish_model.ckpt'\n",
        "  vggish_params.EXAMPLE_HOP_SECONDS = hop_size\n",
        "  \n",
        "  vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
        "\n",
        "  features_tensor = sess.graph.get_tensor_by_name(\n",
        "      vggish_params.INPUT_TENSOR_NAME)\n",
        "  embedding_tensor = sess.graph.get_tensor_by_name(\n",
        "      vggish_params.OUTPUT_TENSOR_NAME)\n",
        "\n",
        "  layers = {'conv1': 'vggish/conv1/Relu',\n",
        "            'pool1': 'vggish/pool1/MaxPool',\n",
        "            'conv2': 'vggish/conv2/Relu',\n",
        "            'pool2': 'vggish/pool2/MaxPool',\n",
        "            'conv3': 'vggish/conv3/conv3_2/Relu',\n",
        "            'pool3': 'vggish/pool3/MaxPool',\n",
        "            'conv4': 'vggish/conv4/conv4_2/Relu',\n",
        "            'pool4': 'vggish/pool4/MaxPool',\n",
        "            'fc1': 'vggish/fc1/fc1_2/Relu',\n",
        "            'fc2': 'vggish/fc2/Relu',\n",
        "            'embedding': 'vggish/embedding',\n",
        "            'features': 'vggish/input_features',\n",
        "         }\n",
        "  g = tf.get_default_graph()\n",
        "  for k in layers:\n",
        "    layers[k] = g.get_tensor_by_name( layers[k] + ':0')\n",
        "    \n",
        "  return {'features': features_tensor,\n",
        "          'embedding': embedding_tensor,\n",
        "          'layers': layers,\n",
        "         }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67EWjWoo9G6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the network\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "vgg = CreateVGGishNetwork(0.96) # The input number represents the duration of the sound file in seconds.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPYpQeiaIKpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EmbeddingsFromVGGish(vgg, x, sr):\n",
        "  '''Run the VGGish model, starting with a sound (x) at sample rate\n",
        "  (sr). Return a dictionary of embeddings from the different layers\n",
        "  of the model.'''\n",
        "  # Produce a batch of log mel spectrogram examples.\n",
        "  input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "  # print('Log Mel Spectrogram example: ', input_batch[0])\n",
        "\n",
        "  layer_names = vgg['layers'].keys()\n",
        "  tensors = [vgg['layers'][k] for k in layer_names]\n",
        "  \n",
        "  results = sess.run(tensors,\n",
        "                     feed_dict={vgg['features']: input_batch})\n",
        "\n",
        "  resdict = {}\n",
        "  for i, k in enumerate(layer_names):\n",
        "    resdict[k] = results[i]\n",
        "    \n",
        "  return resdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTiCuvX8xo-4",
        "colab_type": "code",
        "outputId": "0f684be1-bee9-4a5b-aecf-a679f3ba6397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" \n",
        "Import data into Colab.\n",
        "Load the wav files as a zip file into PWD. Name the zip file as sounds.\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "zip_name = \"sounds.zip\"\n",
        "\n",
        "with ZipFile(zip_name, 'r') as zip:\n",
        "  zip.extractall('sounds')\n",
        "  print(\"Extracted all sound files into the folder named 'sounds'!!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted all sound files into the folder named 'sounds'!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KGPLqTy1r3J",
        "colab_type": "code",
        "outputId": "25162ed7-7609-4b36-bcc2-8e26770e6d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "Load all the files into a list.\n",
        "\"\"\"\n",
        "print(\"The contents of the 'sounds' folder is \")\n",
        "!ls sounds/\n",
        "import glob\n",
        "sounds = glob.glob('sounds/*.wav')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The contents of the 'sounds' folder is \n",
            "acomic.wav  amal.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJKSBjI04EM1",
        "colab_type": "code",
        "outputId": "a486882f-cf32-4298-80e4-2331dc80470e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\"\"\"\n",
        "This code cell extracts embeddings from the sound files added to the list. \n",
        "\"\"\"\n",
        "\n",
        "# Extract embeddings from first sound file.\n",
        "print(\"Extracting embeddings from \" + sounds[0])\n",
        "in_signal, in_sr = sf.read(sounds[0])\n",
        "resdict = EmbeddingsFromVGGish(vgg, in_signal, in_sr)\n",
        "em0 = resdict['embedding']\n",
        "print(\"The shape of em0 is\" + str(em0.shape))\n",
        "em = np.copy(em0)\n",
        "\n",
        "# Extract embeddings from remaining files.\n",
        "for s in sounds[1:]:\n",
        "  print(\"Extracting embeddings from \" + s)\n",
        "  in_signal, in_sr = sf.read(s)\n",
        "  resdict = EmbeddingsFromVGGish(vgg, in_signal, in_sr)\n",
        "  em_s = resdict['embedding']\n",
        "  print(\"The shape of em_s is\" + str(em_s.shape))\n",
        "  em = np.concatenate((em, em_s), axis = 0)\n",
        "  print(\"The shape of em is\" + str(em.shape))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting embeddings from sounds/amal.wav\n",
            "The shape of em0 is(31, 128)\n",
            "Extracting embeddings from sounds/acomic.wav\n",
            "The shape of em_s is(31, 128)\n",
            "The shape of em is(62, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuuER6RGrjWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Store the numpy matrices.\n",
        "\"\"\"\n",
        "np.save(\"embeddings.npy\", em)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHpI6b4nsQhK",
        "colab_type": "code",
        "outputId": "90c87338-811e-41b9-97e3-1e859c451ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "Load the numpy arrays\n",
        "\"\"\"\n",
        "em_load = np.load(\"embeddings.npy\")\n",
        "print(\"em_load shape is {}\".format(em_load.shape))\n",
        "\n",
        "np.array_equal(em, em_load)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "em_load shape is (62, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh6OMPWGPkWL",
        "colab_type": "code",
        "outputId": "02613086-5362-4be0-ac90-3aff177c6450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for k in resdict:\n",
        "  print k, resdict[k].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1 (31, 4096)\n",
            "fc2 (31, 128)\n",
            "features (31, 96, 64)\n",
            "conv3 (31, 24, 16, 256)\n",
            "conv2 (31, 48, 32, 128)\n",
            "conv1 (31, 96, 64, 64)\n",
            "embedding (31, 128)\n",
            "conv4 (31, 12, 8, 512)\n",
            "pool3 (31, 12, 8, 256)\n",
            "pool2 (31, 24, 16, 128)\n",
            "pool1 (31, 48, 32, 64)\n",
            "pool4 (31, 6, 4, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}